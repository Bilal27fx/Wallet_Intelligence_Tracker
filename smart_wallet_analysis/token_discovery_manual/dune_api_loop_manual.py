import os
import json
import yaml
import time
import requests
import pandas as pd
from dotenv import load_dotenv

from smart_wallet_analysis.config import DUNE_YML_PATH, ENV_PATH, TOKEN_DISCOVERY_MANUAL
from smart_wallet_analysis.logger import get_logger
from smart_wallet_analysis.token_discovery_manual.smart_contrat_remover import ContractChecker
from smart_wallet_analysis.token_discovery_manual.wallet_brute_dao import WalletBruteDAO

load_dotenv(dotenv_path=ENV_PATH)

logger = get_logger("token_discovery.manual")

_TDM = TOKEN_DISCOVERY_MANUAL
DUNE_API_KEY = os.getenv("DUNE_API_KEY")
_DAO = WalletBruteDAO()

HEADERS = {
    "Content-Type": "application/json",
    "X-Dune-API-Key": DUNE_API_KEY
}


def execute_dune_query(query_id, parameters):
    """Ex√©cute une requ√™te Dune et retourne un DataFrame."""
    exec_url = f"{_TDM['DUNE_BASE_URL']}/query/{query_id}/execute"
    res = requests.post(exec_url, headers=HEADERS, json={"query_parameters": parameters})
    if res.status_code != 200:
        raise Exception(f"‚ùå Lancement √©chou√© : {res.text}")

    execution_id = res.json()["execution_id"]
    logger.info(f"‚è≥ Execution ID : {execution_id}")

    status_url = f"{_TDM['DUNE_BASE_URL']}/execution/{execution_id}/status"
    result_url = f"{_TDM['DUNE_BASE_URL']}/execution/{execution_id}/results"

    waited = 0
    while waited < _TDM["MAX_WAIT_TIME_SECONDS"]:
        status = requests.get(status_url, headers=HEADERS).json()
        state = status.get("state")
        logger.info(f"‚åõ Status : {state} ‚Äî {waited}s")

        if state == "QUERY_STATE_COMPLETED":
            break
        if state in ["QUERY_STATE_FAILED", "QUERY_STATE_ERRORED"]:
            raise Exception(f"‚ùå Erreur de requ√™te : {state}")

        time.sleep(_TDM["SLEEP_INTERVAL_SECONDS"])
        waited += _TDM["SLEEP_INTERVAL_SECONDS"]

    if waited >= _TDM["MAX_WAIT_TIME_SECONDS"]:
        raise TimeoutError("‚è∞ Timeout d√©pass√©")

    res = requests.get(result_url, headers=HEADERS)
    rows = res.json().get("result", {}).get("rows", [])
    return pd.DataFrame(rows)


def load_dune_config():
    """Charge la configuration Dune depuis le YAML."""
    with open(DUNE_YML_PATH, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def convert_period_to_hours(perf_window):
    """Convertit une p√©riode texte en nombre d'heures."""
    if perf_window.endswith("h"):
        return int(perf_window[:-1])
    if perf_window.endswith("j"):
        return int(perf_window[:-1]) * 24
    if perf_window.endswith("d"):
        return int(perf_window[:-1]) * 24
    try:
        return int(perf_window)
    except ValueError:
        raise ValueError(f"Format de p√©riode non reconnu: {perf_window}")


def load_cache():
    """Charge le cache des tokens d√©j√† trait√©s."""
    if _TDM["CACHE_PATH"].exists():
        try:
            return pd.read_csv(_TDM["CACHE_PATH"])
        except pd.errors.EmptyDataError:
            pass
    return pd.DataFrame(columns=["token_address", "chain", "perf_window"])


def update_cache(df_cache, token_address, chain, perf_window):
    """Ajoute un token au cache local."""
    df_cache.loc[len(df_cache)] = {
        "token_address": token_address,
        "chain": chain,
        "perf_window": perf_window
    }
    _TDM["CACHE_PATH"].parent.mkdir(parents=True, exist_ok=True)
    df_cache.to_csv(_TDM["CACHE_PATH"], index=False)


def filter_eoa_wallets(df):
    """Filtre les wallets pour ne garder que les EOA."""
    try:
        logger.info(f"üîç Filtrage EOA sur {len(df)} wallets...")
        checker = ContractChecker()
        addresses = df["wallet"].unique().tolist()
        logger.info(f"üìä {len(addresses)} adresses uniques √† v√©rifier")

        eoa_addresses = []
        for i, address in enumerate(addresses, 1):
            logger.info(f"  [{i}/{len(addresses)}] V√©rification {address[:10]}...")
            is_contract = checker.is_contract_single(address)

            if is_contract is None:
                logger.warning("    ‚ùå Erreur API, exclusion par s√©curit√©")
                continue
            if is_contract:
                logger.info("    üèóÔ∏è Smart contract d√©tect√©, exclusion")
                continue

            logger.info("    üë§ EOA confirm√©, conservation")
            eoa_addresses.append(address)

            if i < len(addresses):
                time.sleep(_TDM["EOA_CHECK_DELAY_SECONDS"])

        df_filtered = df[df["wallet"].isin(eoa_addresses)]
        logger.info(f"‚úÖ Filtrage termin√©: {len(df_filtered)}/{len(df)} wallets conserv√©s (EOA uniquement)")
        return df_filtered

    except Exception as e:
        logger.error(f"‚ùå Erreur lors du filtrage EOA: {e}")
        logger.warning("‚ö†Ô∏è Conservation de tous les wallets par s√©curit√©")
        return df


def insert_wallets_to_db(df, token_address, token_symbol, chain, temporality):
    """Ins√®re les wallets dans la table wallet_brute apr√®s filtrage EOA."""
    try:
        df_eoa = filter_eoa_wallets(df)

        if df_eoa.empty:
            logger.warning("‚ö†Ô∏è Aucun EOA trouv√© apr√®s filtrage, skip insertion")
            return True

        rows = []
        for _, row in df_eoa.iterrows():
            rows.append(
                {
                    "wallet_address": row["wallet"],
                    "token_address": token_address,
                    "token_symbol": token_symbol,
                    "contract_address": token_address,
                    "chain": chain,
                    "temporality": temporality,
                }
            )

        inserted = _DAO.insert_wallets_batch(rows)
        logger.info("üíæ %s wallets EOA ins√©r√©s dans wallet_brute", inserted)
        return True

    except Exception as e:
        logger.error(f"‚ùå Erreur insertion BDD: {e}")
        return False


def is_already_processed_db(token_address, chain, perf_window):
    """V√©rifie si le token a d√©j√† √©t√© trait√© en base."""
    try:
        return _DAO.token_already_processed(token_address, chain, perf_window)
    except Exception as e:
        logger.error(f"‚ùå Erreur v√©rification BDD: {e}")
        return False


def ensure_wallet_brute_table():
    """Cr√©e la table wallet_brute si elle n'existe pas."""
    return _DAO.ensure_table()


def run_manual_token_discovery():
    """Ex√©cute la d√©couverte de tokens √† partir du JSON manual."""
    if not _TDM["INPUT_JSON_PATH"].exists():
        logger.error(f"‚ùå Fichier d'entr√©e non trouv√©: {_TDM['INPUT_JSON_PATH']}")
        return

    if not ensure_wallet_brute_table():
        logger.error("‚ùå Impossible de cr√©er/v√©rifier la table wallet_brute")
        return

    dune_config = load_dune_config()
    cache_df = load_cache()
    _TDM["EXPORT_DIR"].mkdir(parents=True, exist_ok=True)

    try:
        with open(_TDM["INPUT_JSON_PATH"], "r", encoding="utf-8") as f:
            tokens = json.load(f)
    except Exception as e:
        logger.error(f"‚ùå Erreur lecture JSON: {e}")
        return

    logger.info(f"üöÄ Traitement de {len(tokens)} tokens explosifs")

    for i, token in enumerate(tokens, 1):
        try:
            token_address = token["token_address"].lower()
            perf_window_str = token["perf_window"]
            chain = token["chain"].lower()
            logger.info(f"\n[{i}/{len(tokens)}] üéØ Token: {token_address}")
            logger.info(f"üìä P√©riode: {perf_window_str} | Cha√Æne: {chain}")

        except KeyError as e:
            logger.warning(f"[SKIP] Cl√© manquante dans token {i}: {e}")
            continue

        if is_already_processed_db(token_address, chain, perf_window_str):
            logger.info(f"‚è© D√©j√† trait√© en BDD : {token_address} [{perf_window_str}]")
            continue

        try:
            perf_hours = convert_period_to_hours(perf_window_str)
            token_type = token.get("type", 1)
            extra_hours = _TDM["EARLY_WINDOW_HOURS_BY_TYPE"].get(token_type)

            if extra_hours is None:
                logger.warning(f"‚ö†Ô∏è  Type {token_type} non reconnu, utilisation Type 1 par d√©faut")
                extra_hours = _TDM["EARLY_WINDOW_HOURS_BY_TYPE"].get(1, 24)

            early_hours = perf_hours + extra_hours

            logger.info(f"üìÖ Type {token_type} temporalit√©: accumulation {early_hours}h (perf + {extra_hours}h)")

        except ValueError as e:
            logger.warning(f"[SKIP] {e}")
            continue

        chain_key = _TDM["CHAIN_MAPPING"].get(chain)
        if not chain_key:
            logger.warning(f"[SKIP] Cha√Æne non support√©e: {chain}")
            continue

        query_id = dune_config.get(chain_key, {}).get("top_wallet")
        if not query_id:
            logger.warning(f"[SKIP] Aucune query Dune pour {chain}")
            continue

        params = {
            "token_address": token_address,
            "perf_window": perf_hours,
            "early_window": early_hours
        }

        logger.info(f"[üì°] Query ID : {query_id}")
        logger.info(f"[üîß] Params : perf={perf_hours}h, early={early_hours}h")

        try:
            df = execute_dune_query(query_id, params)
            if df.empty:
                logger.warning("‚ö†Ô∏è Aucun r√©sultat ‚Äî skip")
                update_cache(cache_df, token_address, chain, perf_window_str)
                continue

            token_symbol = token.get("symbol", "UNKNOWN")
            success = insert_wallets_to_db(df, token_address, token_symbol, chain, perf_window_str)

            if success:
                logger.info(f"üìà {len(df)} wallets stock√©s en BDD")

            update_cache(cache_df, token_address, chain, perf_window_str)

        except Exception as e:
            logger.error(f"[‚ùå] Erreur requ√™te : {e}")
            continue

    logger.info("‚úÖ Traitement termin√© !")


def _get_tokens_from_db():
    """R√©cup√®re les tokens explosifs depuis la DB avec leur fen√™tre temporelle."""
    import sqlite3
    from smart_wallet_analysis.config import DB_PATH
    with sqlite3.connect(DB_PATH) as conn:
        rows = conn.execute(
            """SELECT token_address, chain, symbol, hours_since_now
               FROM explosive_tokens_detected
               WHERE hours_since_now IS NOT NULL AND (traite IS NULL OR traite = 0)"""
        ).fetchall()
    return [{"token_address": r[0], "chain": r[1], "symbol": r[2], "hours_since_now": r[3]} for r in rows]


def run_discovery_from_db():
    """D√©couverte automatique depuis explosive_tokens_detected (type 3, perf=hours_since_now)."""
    if not ensure_wallet_brute_table():
        logger.error("Impossible de cr√©er/v√©rifier la table wallet_brute")
        return

    dune_config = load_dune_config()
    tokens = _get_tokens_from_db()
    cache_df = load_cache()

    if not tokens:
        logger.warning("Aucun token avec hours_since_now dans explosive_tokens_detected")
        return

    extra_hours = _TDM["EARLY_WINDOW_HOURS_BY_TYPE"][3]
    logger.info("D√©couverte automatique: %s tokens | type 3 (%sh extra)", len(tokens), extra_hours)

    for i, token in enumerate(tokens, 1):
        token_address = token["token_address"].strip().lower()
        chain = token["chain"].lower()
        symbol = token.get("symbol", "UNKNOWN")
        perf_hours = round(token["hours_since_now"])
        early_hours = perf_hours + extra_hours
        perf_window_str = f"{perf_hours}h"

        logger.info("[%s/%s] %s (%s) | perf=%sh | early=%sh", i, len(tokens), symbol, chain, perf_hours, early_hours)

        already_cached = (
            not cache_df.empty
            and ((cache_df["token_address"] == token_address) & (cache_df["chain"] == chain)).any()
        )
        if already_cached:
            logger.info("D√©j√† dans le cache: %s (%s)", token_address, chain)
            continue

        chain_key = _TDM["CHAIN_MAPPING"].get(chain)
        if not chain_key:
            logger.warning("[SKIP] Cha√Æne non support√©e: %s", chain)
            continue

        query_id = dune_config.get(chain_key, {}).get("top_wallet")
        if not query_id:
            logger.warning("[SKIP] Aucune query Dune pour %s", chain)
            continue

        params = {"token_address": token_address, "perf_window": perf_hours, "early_window": early_hours}

        try:
            df = execute_dune_query(query_id, params)
            if df.empty:
                logger.warning("Aucun r√©sultat Dune pour %s", token_address)
            else:
                insert_wallets_to_db(df, token_address, symbol, chain, perf_window_str)

            import sqlite3 as _sqlite3
            from smart_wallet_analysis.config import DB_PATH as _DB_PATH
            with _sqlite3.connect(_DB_PATH) as conn:
                conn.execute(
                    "UPDATE explosive_tokens_detected SET traite = 1 WHERE token_address = ? AND chain = ?",
                    (token_address, chain),
                )
            update_cache(cache_df, token_address, chain, perf_window_str)
            logger.info("Marqu√© trait√©: %s (%s)", symbol, chain)
        except Exception as e:
            logger.error("Erreur Dune pour %s: %s", token_address, e)

    logger.info("D√©couverte automatique termin√©e")


if __name__ == "__main__":
    run_manual_token_discovery()
